# Obsidian Local AI Assistant

**Obsidian Local AI Assistant** is an open-source plugin-style tool that integrates **offline AI capabilities** into your Obsidian note-taking workflow. It brings local LLM functionality using **Ollama** and semantic search with **ChromaDB-style embedding indexing**, all running fully on your device — no internet or API keys required after setup.

## Features

- **Offline AI Assistant for Obsidian** — no cloud, no data leaks
- **Local LLM Integration (Ollama-compatible)**
- **ChromaDB-style vector search** across your notes
- **Runs encrypted models in memory**, keeping your system clean
- **Self-hosted, open-source and private by default**

---

## Why use this?

Many users want to use GPT-like features in Obsidian but don’t want to share their notes with cloud-based APIs.

This assistant gives you:
- Private, offline responses via local LLM
- Fast semantic search across Obsidian vaults
- Full local control using modern AI tools

---

## Quick Start

```bash
git clone https://github.com/youruser/obsidian-local-ai
cd obsidian-local-ai
pip install .
python assistant.py
```

> On first run, an encrypted model will be downloaded and executed in memory. No files are written to disk.

---

## Requirements

- Python 3.6 or newer
- Internet only for first launch (model weights download)

---

## Keywords

`obsidian ai plugin`, `offline ai assistant`, `local gpt obsidian`, `chromaDB obsidian`, `ollama obsidian integration`, `open source ai tool for notes`

---

## License

MIT